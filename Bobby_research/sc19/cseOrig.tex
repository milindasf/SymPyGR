\documentclass[landscape]{a0poster}
\input{preamble}
\usepackage{geometry}
\usepackage{picins}
\geometry{paperwidth=30in,paperheight=40in,margin=2cm}
\pagestyle{empty}
\setcounter{secnumdepth}{0}
% The textpos package is necessary to position textblocks at arbitary 
% places on the page.
\usepackage[]{textpos}
\usepackage{graphicx,wrapfig}
\usepackage{tikz,pgflibraryshapes}
\usetikzlibrary{shapes,arrows,trees,snakes}

\usepackage{amsmath,amssymb}
\usepackage{color}
\usepackage{setspace}
\usepackage{lipsum}
\onehalfspacing


%% SC18 colors
\definecolor{DarkBlue}{rgb}{0.0,0.1255,0.357}
\definecolor{Red}{rgb}{0.655,0.1,0.185}

% see documentation for a0poster class for the size options here
\let\Textsize\normalsize
%\LARGE
%\def\Head#1{\noindent\hbox to \hsize{\hfil\textbf{\LARGE\color{Red}#1}}\medskip}
\def\Head#1{\noindent{\textbf{\LARGE\color{Red} #1}}\medskip}
\def\LHead#1{\noindent{\Large\color{DarkBlue} #1}\bigskip}
\def\Subhead#1{\noindent{\textbf{\Large\color{DarkBlue} #1}}\medskip}
\def\Title#1{\noindent\textbf{{\VeryHuge\color{Red} #1}}}

\def\Subtitle#1{\noindent\textbf{{\Large\color{Red} #1}}}

\parindent=0pt
\parskip=0.5\baselineskip

\TPGrid[0in,0in]{30}{40}    %(horizontal unit 1in, vertical unit 1in)
\newcommand{\argmax}[1]{\ensuremath{\arg \,\underset{#1}{\max}\;}}


%%%%%%%%% parameters to set column width and other spacing
\def \tpcoulmnwidth{9} 
\def \tpcolIX{11.5}
\def \tpcoulmgap{1.0}
\def \tpblockX{0.5}



\begin{document}

% \tikz[remember picture,overlay] \node[opacity=0.3, inner sep=0pt] at (current page.center){\includegraphics[width=\paperwidth,height=\paperheight]{r1_img5}};

\begin{textblock}{20}(-1,-1) 
\resizebox{18\TPHorizModule}{!}{\includegraphics{../sc18/figs/TopLeft}}
\end{textblock} 

\begin{textblock}{20}(11,38.4) 
	\resizebox{18\TPHorizModule}{!}{\includegraphics{../sc18/figs/BottomRight}}
\end{textblock} 

\begin{textblock}{2}(21,2.5) %<<<
\resizebox{4.5\TPHorizModule}{!}{\includegraphics{../sc18/figs/Ulogo_cmyk}}
\end{textblock} %>>>




%% {{{ Headings 

%\begin{textblock}{5}(14.8,-0.6) %<<<
%	\resizebox{5\TPHorizModule}{!}{\includegraphics{../sc18/figs/dendro}}
%\end{textblock} %>>>



\begin{textblock}{25}(0,1.2) %<<<
	\Title{Machine Specific Symbolic Code Generation}
\end{textblock} %>>>


\begin{textblock}{20}(2.0,4) %<<<
\LHead{{\huge Robert King}, {\Huge Mentors: Hari Sundar, Milinda Fernando}
\hfil\\[1ex]
\textsl{University of Utah}}
\end{textblock}



%% }}}

% COLUMN 1 {{{
	\begin{textblock}{14}(0,6)
	{\color{DarkBlue}\hrule}\medskip	
	\Subhead{Motivation} %%===================================
	
	\vspace{-0.2in}
	The purpose of this work is to improve the run time of the simulation of black hole collisions as seen in the Dendro-Gr framework. The BSSN equations and several other simulation codes consist of several complex partial differential equations and to model these equations the value of each variable is computed once per a time step in the model. The project presented aims to provide a method to increase cache utilization to increase runtime performance.
	\end{textblock} 	

	\begin{textblock}{14}(0, 10.5)
		{\color{DarkBlue}\hrule}\medskip
		\Subhead{Contributions}
		\vspace{-0.2in}
		\begin{itemize}
			\item \textbf{Automatic code-generation}. Given the complexity of the Einstein equations, we have developed an automatic code generation framework for GR using \texttt{SymPy} that automatically generates architecture-optimized codes which helps to improve code portability. 
			\item \textbf{Performance}. Developed a tree isomorphism algorithm for common subexpression elimination. The algorithm aims to improve performance by maximizing the efficiency of the cache. This is done by reducing expression trees into smaller subtrees such the each subtree can be computed within the limits of the cache.
			\item \textbf{Visualization}. 
			Code is able to represent expression trees with Graphiz and visualize expression tree staging	
			%\parpic[r]{\includegraphics[scale=1.5]{cache_miss_plot.png}}
			\parpic[r]{\includegraphics{../sc18/figs/dendro}}		
			\item \textbf{Flexibility}
			Code provides flexibility for any type of expression tree. Code can also be staged for any type of cache architecture. This allows easy adaptability between CPU and GPU codes architectures.
			By providing the target size of the cache the code is able to generate high performance code that can utilize the cache effectively. The results presented were applied to the \texttt{{\dendro\_sym}} project \url{https://arxiv.org/abs/1807.06128}.
			
		
		\end{itemize}
		
	\end{textblock}
	
% }}}

\begin{textblock}{30}(0,19.5)
	{\color{DarkBlue}\hrule}\medskip
	\Head{Methods} %%===================================

	\begin{textblock}{14}(0,0.2)
	This research for consists of two main projects. The first is the subtree isomorphism problem that will focus on the common subexpression elimination and the second is a lower bound analysis for the number of temporary variables needed to solve the partial differential equations. The goal is to create an algorithm that will be able to analyze the different partial differential equations and reorder the temporary variable calculations to maximize cache effectiveness and variable reuse. 

\end{textblock}



\begin{textblock}{14}(-3,12.5)
	\begin{figure}
	\centering
				\includegraphics[scale = 1.8]{tree1_initial.png}
				\caption{Initial Expression Tree}
	\end{figure}
\end{textblock}

\begin{textblock}{14}(5,12.5)
	\begin{figure}
		
	\centering
			\includegraphics[scale=1.4]{tree1_staged.png}
			\caption{Staged Expression Tree}
		\end{figure}

	
\end{textblock}

\begin{textblock}{14}(15,13.5)
	\begin{figure}	
		\centering
			\includegraphics[scale=1.4]{tree1_rebuild.png}
			\caption{Rebuilt Expression Tree}
			
	\end{figure}
\end{textblock}



\begin{textblock}{14}(14.5,0)
	\Subhead{Results}
	%\begin{figure}	
	%	\centering
	%		\includegraphics[scale=2.5]{cache_miss_plot.png}
	%		\caption{Cache Efficiency}
			
	%\end{figure}
	\begin{figure}
		\centering
		%    \includegraphics[width=\linewidth]{../cache_miss_plot.png}
		\begin{tikzpicture}[thick,scale=1.2, every node/.style={scale=1.2}]
		\begin{axis}[legend style={at={(0.8,-0.5)}},anchor=south,xlabel={max. number of dependancies $\rightarrow$},
		symbolic x coords={20,30,50,80,100,200,300},
		xtick = data,
		ylabel={$\%$ of cache misses $\rightarrow$},grid=major,width=20cm,height=10cm,legend columns=2]
		\addplot [red,thick,solid,smooth]table [x={c_size},y = {cm_staged}]{abstract/dat/cache_fontera.dat};
		\addplot [blue,thick,dashed]table [x={c_size},y = {cm_con}]{abstract/dat/cache_fontera.dat};
		\legend{cache adapted, control}
		\end{axis}
		\end{tikzpicture}
		\caption{Number of cache misses based on cache requests for cache adapted code (staged) code vs. the control (unstaged) version of the code in TACC's Fontera supercomputer node }
		\label{fig:cache_results}
		\end{figure}

	\vspace{-0.25in}
	The main area of interest is reducing cache misses when computing the expression trees. Figure 4 demonstrates how the staging size affects the cache efficiency. There is a sweetspot where the staging size is large enough to leverage the entire cache while small enough to not overflow. The goal is adapt the expression trees to sit in the middle of the cache size sweetspot to improve performance. The results presented were run on the Kingspeak Cluster at the University of Utah. The machine consits of Intex Sandybridge processor with 64 KB per core L1 cache, 256 KB per core L2 cache and 20 MB shared L3 cache. On the Kingspeak chpc machines the performance was most effective with cache size of 30. Notice how all staged versions of the code were more cache efficient than the original code. 
\end{textblock}


\begin{textblock}{14}(0,3)
	\Subhead{Staging}

	\vspace{-0.25in}
	The expression DAG contains the desired target variables that solve the Einstein equations, the sources, their corresponding dependencies, the internal nodes, which are calculate from derivates and constants, the sinks. The targets have a significant number of dependecies, the BSSN equation have dependecies on the order of 100s, such that the cache misses occur while calculating the target at each grid point in the mesh. This approach mitigates cache misses by reducing the original expression DAG into smaller sub graphs such that the number of dependencies does not exceed the cache size of the specified machine. In order to maintain correctness some of the dependencies of the original expression graph must be duplicated into multiple subgraphs. Despite computing the expression tree multiple times, the goal is to reduce runtime through increased cache efficiency.
	
\end{textblock}

\begin{textblock}{14}(0,9)
	\Subhead{Rebuilding}% (ORNL's \Titan~ upto $131K$ cores)} 

	\vspace{-0.25in}
	Once the subgraph expressions are created the goal is to order the evaluation of the sub graphs to maintain correctness and maximize cache locality. Expression subgraphs are that are a dependency of another subgraph must be computed first. If several subgraphs have no dependencies, then the subgraphs are order such that graphs with the largest Jaccard Similarity are computed one after another. In doing so variables within the cache can increase usability. 
\end{textblock}

\end{textblock}
%%=== === === SYMBOLIC

\begin{textblock}{14}(14.5,6)
	{\color{DarkBlue}\hrule}\medskip
	\Subhead{Symbolic code generation for \BSSN~ equations}
	\begin{figure}
%	 \noindent\fbox{
			\begin{minipage}[t]{.48\textwidth}
				\small
				\begin{eqnarray*}
					\partial_t \alpha &=&  \mathcal{L}_\beta\alpha - 2 \alpha K, \\
					\partial_t \beta^i &=& \lambda_2 \beta^j\,\partial_j\beta^i + \frac{3}{4} f(\alpha) B^i\\
					\partial_t B^i  &=& \partial_t \tilde\Gamma^i  - \eta B^{i}   + \lambda_3 \beta^j\,\partial_j B^i - \lambda_4 \beta^j\,\partial_j \tilde\Gamma^i \\
					\partial_t \tilde \gamma_{ij} &=&  \mathcal{L}_\beta\tilde{\gamma}_{ij} -2 \alpha \tilde A_{ij}, \\
					\partial_t \chi &=& \mathcal{L}_\beta\chi + \frac{2}{3}\chi \left(\alpha K -  
					\partial_a \beta^a\right)\\
					\partial_t \tilde A_{ij} &=& \mathcal{L}_\beta\tilde{A}_{ij} + \chi \left(-D_i D_j \alpha +
					\alpha R_{ij}\right)^{TF} +\nonumber \\
					&\,&\alpha \left(K \tilde A_{ij} -
					2 \tilde A_{ik} \tilde A^{k}_{\,j}\right), \label{eq:at_evol}\\
					\partial_t K &=& \beta^k\partial_kK- D^i D_i \alpha + \\
					&\,&\alpha \left(\tilde A_{ij}\tilde
					A^{ij} +\frac{1}{3}K^2\right),\\
					\partial_t \tilde \Gamma^i &=& \tilde \gamma^{jk} \partial_j
					\partial_k \beta^i + \frac{1}{3} \tilde \gamma^{ij} \partial_j
					\partial_k \beta^k + \beta^j \partial_j \tilde \Gamma^i - \nonumber \\
					&\,&\tilde
					\Gamma^j \partial_j \beta^i + 
					\frac{2}{3}\tilde \Gamma^i \partial_j
					\beta^j - 2 \tilde A^{i j}\partial_j \alpha + \nonumber \\
					&\,& 2 \alpha \left(\tilde
					{\Gamma^i}_{jk} \tilde A^{jk} - \frac{2}{3 \chi} \tilde A^{ij}\partial_j \chi -
					\frac{2}{3} \tilde \gamma^{ij} \partial_j K\right) \\
					% ~ &~ & ~\\
				\end{eqnarray*}
			\end{minipage}% This must go next to `\end{minipage}`
%		}
	\begin{minipage}[t]{.5\textwidth}
\small
%frame=single,framesep=1pt,
\begin{minted}[frame=single,framesep=1pt,bgcolor=yellow!10]{python}
	
   from DENDRO_sym import *
   a_rhs = Dendro.Lie(b, a) - 2*a*K
   b_rhs = [3/4 * f(a) * B[i] + 
   l2*vec_j_del_j(b, b[i]) for i in e_i]
   l2*vec_j_del_j(b, b[i]) 
   for i in e_i]
   B_rhs = [Gt_rhs[i] - eta * B[i] + 
   l3 * vec_j_del_j(b, B[i]) - 
   l4 * vec_j_del_j(b, Gt[i]) 
   for i in e_i]
   gt_rhs =  Dendro.Lie(b, gt) - 2*a*At
   chi_rhs = Dendro.Lie(b, chi) + 
   2/3*chi*(a*K - del_j(b)) 
   At_rhs = Dendro.Lie(b, At) + chi *
   Dendro.TF(-DiDj(a) + 
   a*Dendro.Ricci) +
   a*(K*At -2*At_ikAtKj)
   K_rhs = vec_k_del_k(K) - DIDi(a) +
   a*(1/3*K*K + A_ij_A_IJ(At)) 
   
\end{minted}
\end{minipage}
%\caption{\label{fig:symb} \small The left panel shows the \BSSN ~formulation of the Einstein equations. These are tensor equations, with indices $i,j,\ldots$ taking the values $1, 2, 3$. On the right we show the \texttt{{\dendro\_sym}} code for these equations. \texttt{\dendro\_sym} uses \texttt{SymPy} and other tools to generate optimized C++ code to evaluate the equations. Note that $\mathcal{L}_\beta,\ D,\ \partial$ denote Lie derivative, covariant derivative and partial derivative respectively, and we have excluded $\partial_t\Gamma^i$ from \texttt{\dendro\_sym} to save space.}
%\label{fig:bssneqs}
\vspace{-0.15in}
\end{figure}
The left panel shows the \BSSN ~formulation of the Einstein equations. These are tensor equations, with indices $i,j,\ldots$ taking the values $1, 2, 3$. On the right we show the \texttt{{\dendro\_sym}} code for these equations. \texttt{\dendro\_sym} uses \texttt{SymPy} and other tools to generate optimized C++ code to evaluate the equations. Note that $\mathcal{L}_\beta,\ D,\ \partial$ denote Lie derivative, covariant derivative and partial derivative respectively, and we have excluded $\partial_t\Gamma^i$ from \texttt{\dendro\_sym} to save space.

%For additional details please refer to {\bf Massively Parallel Simulations of Binary Black Hole Intermediate-%Mass-Ratio Inspirals}, Milinda Fernando, Hari Sundar \url{https://arxiv.org/abs/1807.06128} and the Dendro %project.

	%\includegraphics{../sc18/figs/dendro}}


\end{textblock}







\end{document}

